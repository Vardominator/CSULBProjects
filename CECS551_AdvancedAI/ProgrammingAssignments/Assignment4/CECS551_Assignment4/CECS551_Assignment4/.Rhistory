install.packages("e1071")
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/script.R", encoding = "Windows-1252")
accuracies_table <- accuracies_table[order(Degree, -Cost),]
accuracies_table <- accuracies_table[order("Degre", -"Cost"),]
acc
accuracies_table
current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = 6, type = "C-classification", cost = 1, cross = cross_fold)
print(current_model)
current_model$tot.accuracy
current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = 4, type = "C-classification", cost = 10, cross = cross_fold)
print(current_model$tot.accuracy)
current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = 4, type = "C-classification", cost = 1, cross = cross_fold)
print(current_model$tot.accuracy)
accuracies_table
accuracies_table <- accuracies_table[order(-Cost),]
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table
max_combination <- accuracies_table[which.max(accuracies_table$Degree, accuracies_table$Accuracy),]
max_combination <- accuracies_table[which.max(accuracies_table$Degree, -accuracies_table$Accuracy),]
max_combination <- accuracies_table[which.max( - accuracies_table$Accuracy),]
accuracies_table
max_combination <- accuracies_table[which.max( - accuracies_table$Accuracy),]
max_combination <- max_combination[which.max(max_combination$Degree),]
max_combination
max_combination <- accuracies_table[which.max( -accuracies_table$Accuracy),]
max_combination
accuracies_table
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
print(accuracies_table)
max_combination <- accuracies_table[which.max(accuracies_table$Accuracy),]
max_combination
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
degrees
costs
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_accuracy <- 0
# For each combination perform: 10-fold cross validation and training accuracy from training over the entire data set
accuracies_table <- data.frame("Degree" = integer(), "Cost" = integer(), "Accuracy" = numeric(), stringsAsFactors = FALSE)
for (d in degrees) {
    for (c in costs) {
        current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
        accuracies_table[nrow(accuracies_table) + 1, ] <- c(d, c, current_model$tot.accuracy)
    }
}
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
accuracies_table
max_combination <- accuracies_table[which.max(accuracies_table$Accuracy),]
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_accuracy <- 0
best_predictions
# For each combination perform: 5-fold cross validation and training accuracy from training over the entire data set
accuracies_table <- data.frame("Degree" = integer(), "Cost" = integer(), "Accuracy" = numeric(), stringsAsFactors = FALSE)
for (d in degrees) {
    for (c in costs) {
        current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
        accuracies_table[nrow(accuracies_table) + 1, ] <- c(d, c, current_model$tot.accuracy)
        if (current_model$tot.accuracy > best_accuracy) {
            best_accuracy <- current_model$tot.accuracy
            best_predictions <- predict(current_model, abalone_df[,-length(abalone_df)])
        }
    }
}
# SORT BY INCREASING COMPLEXITY
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
# combination with the highest accuracy
max_combination <- accuracies_table[which.max(accuracies_table$Accuracy),]
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/script.R", encoding = "Windows-1252")
best_predictions
average_distance <- abs(best_predictions - abalone_df$Rings)
length(best_predictions)
length(abalone_df$Rings)
best_predictions[10]
print(best_predictions[10])
print(abalone_df$Rings[10])
class(best_predictions)
class(abalone_df$Rings)
best_predictions <- as.numeric(levels(best_predictions)[best_predictions])
class(best_predictions)
best_predictions <- as.integer(levels(best_predictions)[best_predictions])
class(best_predictions)
class(abalone_df$Rings)
average_distance <- abs(best_predictions - abalone_df$Rings)
average_distance
best_predictions - abalone_df$Rings
print(best_predictions - abalone_df$Rings)
length(best_predictions)
for (d in degrees) {
    for (c in costs) {
        current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
        accuracies_table[nrow(accuracies_table) + 1, ] <- c(d, c, current_model$tot.accuracy)
        if (current_model$tot.accuracy > best_accuracy) {
            best_accuracy <- current_model$tot.accuracy
            best_predictions <- predict(current_model, abalone_df[,-length(abalone_df)])
        }
    }
}
# SORT BY INCREASING COMPLEXITY
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
# combination with the highest accuracy
max_combination <- accuracies_table[which.max(accuracies_table$Accuracy),]
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/script.R", encoding = "Windows-1252")
best_pred_int <- as.integer(best_predictions)
best_pred_int
best_predictions
average_distance <- abs(best_predictions - abalone_df$Rings)
class(best_pred_int)
class(abalone_df$Rings)
average_distance <- best_predictions - abalone_df$Rings
average_distance <- (best_predictions - abalone_df$Rings)
average_distance
type(best_pred_int)
as.type(best_pred_int))
as.type(best_pred_int)
average_distance <- (best_pred_int - abalone_df$Rings)
average_distance
average_distance <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(abs(best_pred_int - abalone_df$Rings))
average_distance
class_distance <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(class_distance)
average_distance <- mean(class_distance)
class_distance <- abs(best_pred_int - abalone_df$Rings)
class_distances <- abs(best_pred_int - abalone_df$Rings)
class_distances
hist(class_distances)
install.packages("ggplot2")
library(ggplot)
library(ggplot2)
ggplot(class_distances) +  geom_histogram(filled.contour="white", color="black") +  geom_vline(aes(xintercept=mean(class_distances)), color="blue", linetype="dashed") +  labs(title="True-Predicted Distance Histogram", x="Class Distances", y="Frequency") +  theme_classic()
ggplot(as.numeric(class_distances)) +  geom_histogram(filled.contour="white", color="black") +  geom_vline(aes(xintercept=mean(class_distances)), color="blue", linetype="dashed") +  labs(title="True-Predicted Distance Histogram", x="Class Distances", y="Frequency") +  theme_classic()
ggplot(as.data.frame(class_distances)) +  geom_histogram(filled.contour="white", color="black") +  geom_vline(aes(xintercept=mean(class_distances)), color="blue", linetype="dashed") +  labs(title="True-Predicted Distance Histogram", x="Class Distances", y="Frequency") +  theme_classic()
ggplot(as.data.frame(class_distances)) +  geom_histogram(fill="white", color="black") +  geom_vline(aes(xintercept=mean(class_distances)), color="blue", linetype="dashed") +  labs(title="True-Predicted Distance Histogram", x="Class Distances", y="Frequency") +  theme_classic()
hist(class_distances)
# IMPORT LIBRARY
#install.packages("e1071")
library(e1071)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("data.tree")
library(data.tree)
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_accuracy <- 0
best_predictions <- data.frame()
# IMPORT LIBRARY
#install.packages("e1071")
library(e1071)
#install.packages("ggplot2")
library(ggplot2)
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_accuracy <- 0
best_predictions <- data.frame()
max_rings <- max(abalone_df$Rings)
f1 <- list(c(0:9), c(10:max_rings))
f2 <- list(c(0:7), c(8:9))
f3 <- list(c(0:5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:max_rings))
f7 <- list(c(12:13), c(14:max_rings))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifiers <- c()
# exercise 2: best learning-parameter(BLP) with binary classifiers
binary_classifier <- function(df, degrees, costs, negative_class, positive_class) {
    # given the dataframe and bounds, degrees, and costs, will return
    #   the size of the subset, degree, cost, average CV accuracy of the BLP combinations,
    #   and the best accuracy
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    best_model <- 0
    num_of_combos <- length(costs) * length(degrees)
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            predictions <- predict(model, df[, - length(df)])
            accuracy <- mean(predictions == df[, length(df)])
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    return(c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy, best_model))
}
for (bound in classifier_bounds) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifer[-length(classifier)]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
}
# exercise 2: best learning-parameter(BLP) with binary classifiers
binary_classifier <- function(df, degrees, costs, negative_class, positive_class) {
    # given the dataframe and bounds, degrees, and costs, will return
    #   the size of the subset, degree, cost, average CV accuracy of the BLP combinations,
    #   and the best accuracy
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    best_model <- 0
    num_of_combos <- length(costs) * length(degrees)
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            #predictions <- predict(model, df[, - length(df)])
            #accuracy <- mean(predictions == df[, length(df)])
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    return(c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy, best_model))
}
for (bound in classifier_bounds) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifer[-length(classifier)]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
}
print(binary_classifier_table)
binary_classifier_models <- c()
for (bound in classifier_bounds) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifer[-length(classifier)]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
binary_classifier_models <- c()
for (bound in classifier_bounds) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifer[1:length(classifier) - 1]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
abs <- c(1,2,3,4,5)
abs[length(abs)]
abs[1:length(abs) - 1]
d < abs[1:length(abs) - 1]
d <- abs[1:length(abs) - 1]
d
binary_classifier_models <- c()
for (bound in classifier_bounds) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
for (bound in classifier_bounds[2:2]) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
for (bound in classifier_bounds[2:2]) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    binary_classifiers <- c(binary_classifiers, classifier[length(classifier)])
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
binary_classifier_models <- c()
for (bound in classifier_bounds[2:2]) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
binary_classifier_models <- c()
for (bound in classifier_bounds[2:2]) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    #binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
binary_classifier_models <- c()
for (bound in classifier_bounds[2:2]) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    #binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    #binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
classifier
length(classifier)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
for (bound in classifier_bounds[2:2]) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    #binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
for (bound in classifier_bounds) {
    classifier <- binary_classifier(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    #binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier[1:length(classifier) - 1]
    binary_classifier_models <- c(binary_classifier_models, classifier[length(classifier)])
}
print(binary_classifier_table)
length(binary_classifier_models)
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
abalone_df$Rings
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/BinaryClassifierParams.R", encoding = "Windows-1252")
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/BinaryClassifierModel.R", encoding = "Windows-1252")
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/BinaryClassifierParams.R", encoding = "Windows-1252")
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/BinaryClassifierParams.R", encoding = "Windows-1252")
source("F:/GitHub/CSULBProjects/CECS551_AdvancedAI/ProgrammingAssignments/Assignment4/CECS551_Assignment4/CECS551_Assignment4/BinaryClassifierModel.R", encoding = "Windows-1252")
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- c()
for (bound in classifier_bounds) {
    classifier <- binary_classifier_model(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_models <- c(binary_classifier_models, classifier)
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier_params
}
print(binary_classifier_table)
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
for (i in 1:nrow(abalone_df)) {
    print(abalone_df[i,])
}
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
for (i in 1:nrow(abalone_df)) {
    print(abalone_df[i,]$Rings)
}
binary_model_predictions <- c()
for (i in 5) {
    #print(abalone_df[i,]$Rings)
    current_feature_vector <- abalone_df[, - length(abalone_df)]
    print(current_feature_vector)
    #head_model <- binary_classifier_models[1]
    #prediction <- predict(head_model, abalone_df[i, ])
}
binary_model_predictions <- c()
for (i in 5) {
    #print(abalone_df[i,]$Rings)
    current_feature_vector <- abalone_df[i, - length(abalone_df)]
    print(current_feature_vector)
    #head_model <- binary_classifier_models[1]
    #prediction <- predict(head_model, abalone_df[i, ])
}
binary_model_predictions <- c()
for (i in 5) {
    #print(abalone_df[i,]$Rings)
    current_feature_vector <- abalone_df[i, - length(abalone_df)]
    print(current_feature_vector)
    head_model <- binary_classifier_models[1]
    prediction <- predict(head_model, current_feature_vector)
}
class(binary_classifier_models[1])
binary_classifier_models[1]
binary_classifier_models[2]
binary_classifier_models[3]
binary_classifier_models[4]
binary_classifier_models[5]
binary_classifier_models[6]
binary_classifier_models[1]
length(binary_classifier_models)
binary_classifier_models <- list()
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    classifier <- binary_classifier_model(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier_params
}
print(binary_classifier_table)
length(binary_classifier_models)
binary_classifier_models[1]
binary_classifier_models[[1]]
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
class(binary_classifier_models[1])
binary_model_predictions <- c()
for (i in 5) {
    head_model <- binary_classifier_models[[1]]
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df))
}
binary_model_predictions <- c()
for (i in 1) {
    head_model <- binary_classifier_models[1]
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df)])
}
binary_model_predictions <- c()
for (i in 1) {
    head_model <- binary_classifier_models[[1]]
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df)])
}
prediction
binary_model_predictions <- c()
for (i in 1) {
    head_model <- binary_classifier_models[[1]]
    print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df)])
}
binary_model_predictions <- c()
for (i in 1) {
    head_model <- binary_classifier_models[[1]]
    print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df)])
    print(prediction)
}
binary_model_predictions <- c()
for (i in 1) {
    head_model <- binary_classifier_models[[1]]
    print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df)])
    print(prediction == 1)
}
binary_model_predictions <- c()
for (i in 1) {
    head_model <- binary_classifier_models[[1]]
    print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(head_model, abalone_df[i, - length(abalone_df)])
    print(prediction == -1)
}
binary_model_predictions <- c()
for (i in 10) {
    model <- binary_classifier_models[[1]]
    #print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    #print(prediction == -1)
    # prediction <= 9
    if (prediction == -1) {
        print("no")
    } else {
        print("yes")
    }
}
binary_model_predictions <- c()
for (i in nrow(df)) {
    model <- binary_classifier_models[[1]]
    #print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    #print(prediction == -1)
    # prediction <= 9
    if (prediction == -1) {
        print("no")
    } else {
        print("yes")
    }
}
binary_model_predictions <- c()
for (i in nrow(df)) {
    model <- binary_classifier_models[[1]]
    #print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    #print(prediction == -1)
    print(prediction)
    # prediction <= 9
    if (prediction == -1) {
        print("no")
    } else {
        print("yes")
    }
}
binary_model_predictions <- c()
for (i in nrow(df)) {
    model <- binary_classifier_models[[1]]
    #print(abalone_df[i, - length(abalone_df)])
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    #print(prediction == -1)
    print(predict(model, abalone_df[i, - length(abalone_df)]))
    # prediction <= 9
    if (prediction == -1) {
        print("no")
    } else {
        print("yes")
    }
}
if (prediction == -1) {                 # final prediction is 10     final_predictions <- c()     binary_model_predictions <- c()     for (i in nrow(df)) {         # <= 9 or >= 10         model <- binary_classifier_models[[1]]         prediction <- predict(model, abalone_df[i, - length(abalone_df)])         if (prediction == 1) {             # prediction >= 10             # 10-11 or >= 12             model <- binary_classifier_models[[6]]             prediction <- predict(model, abalone_df[i, - length(abalone_df)])             if (prediction == 1) {                 # prediction >= 12                 # 12-13 or >= 14                 model <- binary_classifier_models[[7]]                 prediction <- predict(model, abalone_df[i, - length(abalone_df)])                 if (prediction == 1) {                     # final prediction is 14                     final_predictions <- c(final_predictions, 14)                 } else {                     # 12 or 13                     model <- binary_classifier_models[[9]]                     prediction <- predict(model, abalone_df[i, - length(abalone_df)])                     if (prediction == 1) {                         # final prediction is 13                         final_predictions <- c(final_predictions, 13)                     } else {                         # final prediction is 12                         final_predictions <- c(final_predictions, 12)                     }                 }             } else if (prediction == -1) {                 # prediction 10-11                 model <- binary_classifier_models[[8]]                 prediction <- predict(model, abalone_df[i, - length(abalone_df)])                 if (prediction == 1) {                     # final prediction is 11                     final_predictions <- c(final_predictions, 11)                 } else {                     # final prediction is 10                     final_predictions <- c(final_predictions, 10)                 }             }         } else if (prediction == -1) {             # prediction <= 9             # <= 7 or 8-9             model <- binary_classifier_models[[2]]             prediction <- predict(model, abalone_df[i, - length(abalone_df)])             if (prediction == 1) {                 # prediction 8-9                 model <- binary_classifier_models[[4]]                 prediction <- predict(model, abalone_df[i, - length(abalone_df)])                 if (prediction == 1) {                     # final prediction is 9                     final_predictions <- c(final_predictions, 9)                 } else {                     # final prediction is 8                     final_predictions <- c(final_predictions, 8)                 }             } else if (prediction == -1) {                 # prediction <= 7                 # <= 5 or 6-7                 model <- binary_classifier_models[[3]]                 prediction <- predict(model, abalone_df[i, - length(abalone_df)])                 if (prediction == 1) {                     # prediction 6-7                     model <- binary_classifier_models[[5]]                     prediction <- predict(model, abalone_df[i, - length(abalone_df)])                     if (prediction == 1) {                         # final prediction is 7                         final_predictions <- c(final_predictions, 7)                     } else {                         # final prediction is 6                         final_predictions <- c(final_predictions, 6)                     }                 } else if (prediction == -1) {                     # final prediction is 5                     final_predictions <- c(final_predictions, 5)                 }             }         }     } }
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
final_predictions <- c()
binary_model_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else if (prediction == -1) {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else if (prediction == -1) {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else if (prediction == -1) {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
final_predictions
mod <- binary_classifier_models[1]
mod <- binary_classifier_models[1]
prediction <- predict(model, abalone_df[10, - length(abalone_df)])
prediction
prediction == 1
prediction == -1
final_predictions <- c()
mod <- binary_classifier_models[1]
binary_model_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else if (prediction == -1){
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else if (prediction == -1) {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else if (prediction == -1) {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else if (prediction == -1) {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
final_predictions <- c()
mod <- binary_classifier_models[1]
binary_model_predictions <- c()
for (i in nrow(df)) {
    print(i)
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else if (prediction == -1){
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else if (prediction == -1) {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else if (prediction == -1) {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else if (prediction == -1) {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
nrow(abalone_df)
model <- binary_classifier_models[[1]]
prediction <- predict(model, abalone_df[1, - length(abalone_df)])
prediction==1
prediction == -1
model <- binary_classifier_models[[8]]
prediction <- predict(model, abalone_df[1, - length(abalone_df)])
prediction == -1
abalone_df[1,]
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
final_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else if (prediction == -1){
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else if (prediction == -1) {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else if (prediction == -1) {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else if (prediction == -1) {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
final_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else if (prediction == -1){
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else if (prediction == -1) {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else if (prediction == -1) {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else if (prediction == -1) {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
final_predictions
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
final_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        flush.console()
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else if (prediction == -1){
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else if (prediction == -1) {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else if (prediction == -1) {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else if (prediction == -1) {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
binary_classifier[6]
binary_classifier[[6]]
binary_classifier_models[[6]]
binary_classifier_models[[9]]
binary_classifier_models[[1]]
binary_classifier_models[[3]]
binary_classifier_models[[5]]
binary_classifier_models[[8]]
final_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        flush.console()
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
prediction
final_predictions
final_predictions <- c(12)
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        flush.console()
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
final_predictions
final_predictions <- c()
for (i in nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        flush.console()
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
binary_classifier_models
final_predictions <- c()
for (i in 1:nrow(df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        flush.console()
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
final_predictions <- c()
for (i in 1:nrow(abalone_df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        print(prediction)
        flush.console()
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
final_predictions
final_predictions
class(final_predictions)
class(abalone_df$Rings)
final_predictions == abalone_df
final_predictions == abalone_df$Rings
mean(final_predictions==abalone_df$Rings)
max(final_predictions)
max(abalone_df$Rings)
min(final_predictions)
min(abalone_df$Rings)
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(0:9), c(10:14))
f2 <- list(c(0:7), c(8:9))
f3 <- list(c(5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:14))
f7 <- list(c(12:13), c(14))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # BUILD MODEL AND APPEND TO MODELS LIST
    classifier <- binary_classifier_model(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier_params
}
print(binary_classifier_table)
print(binary_classifier_table)
final_predictions <- c()
for (i in 1:nrow(abalone_df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
length(final_predictions)
final_predictions == abalone_df$Rings
mean(final_predictions == abalone_df$Rings)
length(final_predictions)
# exercise 2: best learning-parameter(BLP) with binary classifiers
binary_classifier_params <- function(df, degrees, costs, negative_class, positive_class) {
    # given the dataframe and bounds, degrees, and costs, will return
    #   the size of the subset, degree, cost, average CV accuracy of the BLP combinations,
    #   and the best accuracy
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
            }
        }
    }
    return(c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy))
}
binary_classifier_model <- function(df, degrees, costs, negative_class, positive_class) {
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    return(best_model)
}
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(5:9), c(10:14))
f2 <- list(c(5:7), c(8:9))
f3 <- list(c(5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:14))
f7 <- list(c(12:13), c(14))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
binary_classifier_table
# exercise 2: best learning-parameter(BLP) with binary classifiers
binary_classifier_params <- function(df, degrees, costs, negative_class, positive_class) {
    # given the dataframe and bounds, degrees, and costs, will return
    #   the size of the subset, degree, cost, average CV accuracy of the BLP combinations,
    #   and the best accuracy
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    return(c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy, best_model))
}
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(5:9), c(10:14))
f2 <- list(c(5:7), c(8:9))
f3 <- list(c(5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:14))
f7 <- list(c(12:13), c(14))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier_params[1:length(classifier_params) - 1]
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier_bounds[length(classifier_params)]
}
print(binary_classifier_table)
print(binary_classifier_models)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds[1:1]) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- classifier_params[1:length(classifier_params) - 1]
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier_params[length(classifier_params)]
}
print(binary_classifier_table)
print(binary_classifier_models)
l <- list(1,2,3,4)
l[1]
l[1:2]
v <- unlist(l)
v
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds[1:1]) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- unlist(classifier_params[1:length(classifier_params) - 1])
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier_params[length(classifier_params)]
}
print(binary_classifier_table)
print(binary_classifier_models)
v <- unlist(l)
v
v <- unlist(1[1:2])
v
v <- unlist(l[1:2])
v
v <- unlist(l[1:length(l) - 1])
v
blah <- l[length(l)]
blah <- l[length(l)]
blah
binary_classifier_table
binary_classifier_model
binary_classifier_models
binary_classifier_models[1]
binary_classifier_models[2]
binary_classifier_models[[1]]
type(binary_classifier_models)
class(binary_classifier_models)
class(binary_classifier_models[1])
length(binary_classifier_models[1])
class(binary_classifier_models[1])
classifier_params
class(classifier_params)
binary_classifier_models[[6]]
binary_classifier_models[[1]]
prediction <- predict(binary_classifier_models[[1]], abalone_df[10, - length(abalone_df)])
# exercise 2: best learning-parameter(BLP) with binary classifiers
binary_classifier_params <- function(df, degrees, costs, negative_class, positive_class) {
    # given the dataframe and bounds, degrees, and costs, will return
    #   the size of the subset, degree, cost, average CV accuracy of the BLP combinations,
    #   and the best accuracy
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    return(list(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy, list(best_model)))
}
binary_classifier_models <- list()
for (bound in classifier_bounds[1:1]) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- unlist(classifier_params[1:length(classifier_params) - 1])
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier_params[length(classifier_params)]
}
print(binary_classifier_table)
print(binary_classifier_models)
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- unlist(classifier_params[1:length(classifier_params) - 1])
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- classifier_params[length(classifier_params)]
}
print(binary_classifier_table)
print(binary_classifier_models)
final_predictions <- c()
for (i in 1:nrow(abalone_df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
binary_classifier_models[[1]]
model <- binary_classifier_models[[1]]
prediction <- predict(model, abalone_df[10, - length(abalone_df)])
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds[1:1]) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    classifier_params <- classifier <- binary_classifier_params(abalone_df, degrees, costs, bound[[1]], bound[[2]])
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- unlist(classifier_params[1:length(classifier_params) - 1])
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- unlist(classifier_params[length(classifier_params)])
}
print(binary_classifier_table)
print(binary_classifier_models)
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(5:9), c(10:14))
f2 <- list(c(5:7), c(8:9))
f3 <- list(c(5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:14))
f7 <- list(c(12:13), c(14))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    negative_class <- bound[[1]]
    positive_class <- bound[[2]]
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- abalone_df
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy)
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- best_model
}
print(binary_classifier_table)
print(binary_classifier_models)
class(binary_classifier_models[[1]])
binary_classifier_table[1]
binary_classifier_table
for (i in 1:nrow(abalone_df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
accuracy <- mean(final_predictions==abalone_df$Rings))
accuracy <- mean(final_predictions==abalone_df$Rings)
accuracy
binary_classifier_table
binary_classifier_models[[3]]
abalone_df[10,]
m <- binary_classifier_models[[1]]
prediction <- predict(m, abalone_df[10, - length(abalone_df)])
prediction == 1
m <- binary_classifier_models[[6]]
prediction <- predict(m, abalone_df[10, - length(abalone_df)])
prediction == 1
model <- binary_classifier_models[[7]]
prediction <- predict(model, abalone_df[10, - length(abalone_df)])
prediction == 1
final_predictions[10]
abalone_df[10, length(abalone_df)]
final_predictions[1100]
abalone_df[1100, length(abalone_df)]
final_predictions[1250]
abalone_df[1250, length(abalone_df)]
abalone_df[4000, length(abalone_df)]
final_predictions[4000]
binary_class_distances <- abs(final_predictions - abalone_df$Rings)
binary_average_distance <- mean(binary_class_distances)
binary_average_distance
hist(binary_class_distances)
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_accuracy <- 0
best_predictions <- data.frame()
# For each combination perform: 5-fold cross validation and training accuracy from training over the entire data set
accuracies_table <- data.frame("Degree" = integer(), "Cost" = numeric(), "Accuracy" = numeric(), stringsAsFactors = FALSE)
for (d in degrees) {
    for (c in costs) {
        current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
        accuracies_table[nrow(accuracies_table) + 1, ] <- c(d, c, current_model$tot.accuracy)
        if (current_model$tot.accuracy > best_accuracy) {
            best_accuracy <- current_model$tot.accuracy
            best_predictions <- predict(current_model, abalone_df[,-length(abalone_df)])
        }
    }
}
# SORT BY INCREASING COMPLEXITY
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
# combination with the highest accuracy
max_combination <- accuracies_table[which.max(accuracies_table$Accuracy),]
best_pred_int <- as.integer(best_predictions)
# for the best classifier in the table, provide the average distance of the predicted class from the true class
class_distances <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(class_distance)
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
hist(class_distances)
best_pred_int <- as.integer(best_predictions)
# for the best classifier in the table, provide the average distance of the predicted class from the true class
class_distances <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(class_distances)
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
hist(class_distances)
average_distance
binary_average_distance
reg_df <- read.table("Exercise-4.csv")
reg_df <- read.csv("Exercise-4.csv")
reg_df
reg_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = 2, type = "eps=regression")
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(reg_df, kernel = "polynomial", degree = 2, type = "eps=regression")
reg_model <- svm(X ~ ., data=reg_df, kernel = "polynomial", degree = 2, type = "eps=regression")
reg_model <- svm(Y ~ X, data=reg_df, kernel = "polynomial", degree = 2, type = "eps=regression")
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
abline(reg_model)
abline(reg_model)
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
abline(reg_model)
plot(reg_df, pch = 16)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
points(reg_df$X, reg_model, col="red", pch=4)
reg_df$X
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col="red", pch=4)
points(reg_df$X, predicted, col="red", pch=4, type="l")
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col="red", pch=4, type="l")
points(reg_df$X, predicted, col="red", pch=3, type="l")
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col="red", pch=3, type="l")
points(reg_df$X, predicted, col="red", pch=3)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col="red", pch=3)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
lines(reg_df$X, predicted, col="red", pch=3)
plot(reg_df$X, predicted, col="red", pch=3)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
lines(reg_df$X, predicted, col="red", pch=3, type="o")
lines(reg_df$X, predicted, col="red", pch=3)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
lines(reg_df$X, predicted, col="red", pch=3)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
lines(reg_df$X, predicted, col="red", pch=3)
points(reg_df$X, predicted, col="red", pch=4)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col="red", pch=4)
title("Data Points with Fitted Line")
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
hist(class_distances)
title("Histogram of Binary Class Distances")
hist(class_distances, main="Histogram of Binary Class Distances")
hist(class_distances, main="Histogram of Class Distances")
hist(binary_class_distances, main = "Histogram of Binary Class Distances")
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df,kernel="polynomial", degree=2,type="eps-regression")
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
epsilons <- c(1:2:.5)
reg_costs <- c(10 ^ (-1:2))
epsilons <- c(1,1.25,1.5,1.75)
length(epsilons) * length(reg_costs)
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:2))
epsilons <- c(1, 1.25, 1.5, 1.75)
best_reg_accuracy <- 0
best_reg_c <- 0
best_reg_e <- 0
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        if (reg_model$tot.nSV) {
            best_reg_accuracy <- reg_model$tot.nSV
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
best_reg_accuracy
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:2))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 100000
best_reg_c <- 0
best_reg_e <- 0
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse < reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
lowest_mse
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        print(reg_model$tot.MSE)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse < reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-3:4))
epsilons <- c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        print(reg_model$tot.MSE)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse < reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
length(reg_costs)
reg_costs <- c(10 ^ (-1:3))
length(reg_costs)
length(epsilons)
epsilons <- c(0.75, 1, 1.25, 1.5, 1.75)
length(epsilons)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df,kernel="polynomial", degree=2,type="eps-regression")
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        print(reg_model$tot.MSE)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
lowest_mse
accuracies_table <- data.frame("Degree" = integer(), "Cost" = numeric(), "CV Accuracy" = numeric(), "Entire DF Accuracy" = numeric(), stringsAsFactors = FALSE)
for (d in degrees) {
    for (c in costs) {
        current_model_entire_df <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c)
        predictions <- predict(current_model_entire_df, abalone_df[, - length(abalone_df)])
        accuracy_total <- 100 * mean(predictions == abalone_df[, length(abalone_df)])
        current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
        accuracies_table[nrow(accuracies_table) + 1,] <- c(d, c, current_model$tot.accuracy, accuracy_total)
        if (current_model$tot.accuracy > best_accuracy) {
            best_accuracy <- current_model$tot.accuracy
            best_predictions <- predict(current_model, abalone_df[,-length(abalone_df)])
        }
    }
}
# SORT BY INCREASING COMPLEXITY
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
accuracies_table
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
mse_entire
lowest_mse
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_model <- svm(Y ~ X,reg_df,kernel="polynomial", degree=2,type="eps-regression")
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
        }
    }
}
reg_accuracies_table
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, reg_df)
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
length(reg_df)
nrows(reg_df)
nrow(reg_df)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
seq(1, 10, length.out = 1000)
best_regreg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
points(seq(1, 10, length.out = 1000), predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
length(seq(1, 10, length.out = 1000))
length(predicted)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
points(seq(1, 10, length.out = 1000), predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
#predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
points(seq(1, 10, length.out = 1000), predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
predicted <- predict(best_reg_model, seq(1,10,length.out=1000))
predicted <- predict(best_reg_model, 200)
plot(reg_df, pch = 16)
predicted <- predict(reg_model, reg_df)
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
predicted <- predict(reg_model, seq(1, 10, length.out = 1000))
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
predicted <- predict(best_reg_model, seq(1, 10, length.out = 1000))
points(reg_df$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
test_data <- data.frame("X" = numeric(), stringsAsFactors = FALSE)
test_data <- data.frame("X" = numeric(), stringsAsFactors = FALSE)
test_data[nrow(test_data) + 1,] <- seq(1, 10, length.out = 1000)
test_data <- data.frame()
test_data["X"] <- seq(1, 10, length.out = 1000)
test_data <- data.frame("X" = numeric(), stringsAsFactors = FALSE)
test_data
test_data$X <- seq(1, 10, length.out = 1000)
test_data <- data.frame(seq(1, 10, length.out = 1000))
test_data
test_data <- data.frame(seq(1, 10, length.out = 1000), colnames = c("X"))
test_data <- data.frame(seq(1, 10, length.out = 1000), colnames = c("X"))
nrow(test_data)
ncol(test_data)
test_data$X
test_data <- data.frame(seq(1, 10, length.out = 1000))
ncol(test_data)
nrow(test_data)
test_data <- data.frame(seq(1, 10, length.out = 1000))
predicted <- predict(best_reg_model, test_data)
test_data <- data.frame(seq(1, 10, length.out = 1000))
colnames(test_data) <- c("X")
head(test_dat)
head(test_data)
predicted <- predict(best_reg_model, test_data)
points(reg_df$X, predicted, col = "red", pch = 4)
plot(reg_df, pch = 16)
test_data <- data.frame(seq(1, 10, length.out = 1000))
colnames(test_data) <- c("X")
predicted <- predict(best_reg_model, test_data)
points(test_data$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
test_data <- data.frame(seq(0, 10, length.out = 1000))
colnames(test_data) <- c("X")
predicted <- predict(best_reg_model, test_data)
points(test_data$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
# SORT BY INCREASING COMPLEXITY
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
# combination with the highest accuracy
max_combination <- accuracies_table[which.max(accuracies_table$CV.Accuracy),]
max_combination
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
# combination with the CV highest accuracy
reg_max_combination <- reg_accuracies_table[which.max(reg_accuracies_table$CV.MSE),]
reg_max_combination
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
# combination with the CV highest accuracy
reg_max_combination <- reg_accuracies_table[which.min(reg_accuracies_table$CV.MSE),]
reg_max_combination
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
            mse_entire <- mean(reg_model_entire$residuals ^ 2)
            reg_model <- svm(Rings ~ ., reg_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model <- reg_model
            }
        }
    }
}
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model <- reg_model
            }
        }
    }
}
best_reg_c_abalone
best_reg_d_abalone
best_reg_e_abalone
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
best_reg_model_abalone
best_reg_model
predicted_reg_abalone <- predict(best_reg_model, abalone_df[, - length(df)])
predicted_reg_abalone
average_distance_reg_abalone <- mean(abs(predicted_reg_abalone - abalone_df[, length(df)]))
average_distance_reg_abalone
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
average_distance_reg_abalone
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])average_distance_reg_abalone
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances")
# IMPORTLIBRARY
#install.packages("e1071")
library(e1071)
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_cv_accuracy <- 0
best_predictions <- data.frame()
# For each combination perform: 5-fold cross validation and training accuracy from training over the entire data set
accuracies_table <- data.frame("Degree" = integer(), "Cost" = numeric(), "CV Accuracy" = numeric(), "Entire DF Accuracy" = numeric(), stringsAsFactors = FALSE)
for (d in degrees) {
    for (c in costs) {
        current_model_entire_df <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c)
        predictions <- predict(current_model_entire_df, abalone_df[, - length(abalone_df)])
        accuracy_total <- 100 * mean(predictions == abalone_df[, length(abalone_df)])
        current_model <- svm(Rings ~ ., data = abalone_df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
        accuracies_table[nrow(accuracies_table) + 1,] <- c(d, c, current_model$tot.accuracy, accuracy_total)
        if (current_model$tot.accuracy > best_cv_accuracy) {
            best_cv_accuracy <- current_model$tot.accuracy
            best_predictions <- predict(current_model, abalone_df[,-length(abalone_df)])
        }
    }
}
# SORT BY INCREASING COMPLEXITY
accuracies_table <- accuracies_table[order(-accuracies_table$Cost),]
accuracies_table <- accuracies_table[order(accuracies_table$Degree),]
# combination with the CV highest accuracy
max_combination <- accuracies_table[which.max(accuracies_table$CV.Accuracy),]
best_pred_int <- as.integer(best_predictions)
# for the best classifier in the table, provide the average distance of the predicted class from the true class
class_distances <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(class_distances)
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
hist(class_distances, main="Histogram of Class Distances")
accuracies_table
max_combination <- accuracies_table[which.max(accuracies_table$CV.Accuracy),]
max_combination
class_distances <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(class_distances)
average_distance
class_distances <- abs(best_pred_int - abalone_df$Rings)
average_distance <- mean(class_distances)
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
hist(class_distances, main="Histogram of Class Distances")
axis(labels=seq(0,10,1))
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
hist(class_distances, main="Histogram of Class Distances")
axis(side=1, labels=seq(0,10,1))
hist(class_distances, main="Histogram of Class Distances")
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
hist(class_distances, main="Histogram of Class Distances", xlab = "Distance", ylab = "Frequency")
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency")
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
par(bg = 'blue')
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
par(bg = 'gray')
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
# provide a histogram that shows the frequency of how often a prediction is m rings away from the true number of rings
par(bg = 'cream')
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
par(bg = 'white')
hist(class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side=1, at=seq(0,10,1), labels=seq(0,10,1))
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(0:9), c(10:30))
f2 <- list(c(0:7), c(8:9))
f3 <- list(c(0:5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:30))
f7 <- list(c(12:13), c(14:30))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    negative_class <- bound[[1]]
    positive_class <- bound[[2]]
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- abalone_df
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy)
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- best_model
}
print(binary_classifier_table)
binary_classifier_table
options(digits=4)
binary_classifier_table
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(0:9), c(10:30))
f2 <- list(c(0:7), c(8:9))
f3 <- list(c(0:5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:30))
f7 <- list(c(12:13), c(14:30))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    negative_class <- bound[[1]]
    positive_class <- bound[[2]]
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[0])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- abalone_df
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy)
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- best_model
}
binary_classifier_table
final_predictions <- c()
for (i in 1:nrow(abalone_df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
binary_class_accuracy <- mean(final_predictions == abalone_df$Rings)
binary_class_distances <- abs(final_predictions - abalone_df$Rings)
binary_average_distance <- mean(binary_class_distances)
binary_class_accuracy
binary_average_distance
hist(binary_class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side = 1, at = seq(0, 10, 1), labels = seq(0, 10, 1))
hist(binary_class_distances, main = "Histogram of Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 8))
axis(side = 1, at = seq(0, 10, 1), labels = seq(0, 10, 1))
hist(binary_class_distances, main = "Histogram of Binary Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 8))
axis(side = 1, at = seq(0, 10, 1), labels = seq(0, 10, 1))
library(e1071)
#EXERCISE 1
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
# make all less than 5 = 5
abalone_df$Rings[abalone_df$Rings < 5] <- 5
# make all greater than 14 = 14
abalone_df$Rings[abalone_df$Rings > 14] <- 14
f1 <- list(c(0:9), c(10:30))
f2 <- list(c(0:7), c(8:9))
f3 <- list(c(0:5), c(6:7))
f4 <- list(c(8), c(9))
f5 <- list(c(6), c(7))
f6 <- list(c(10:11), c(12:30))
f7 <- list(c(12:13), c(14:30))
f8 <- list(c(10), c(11))
f9 <- list(c(12), c(13))
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
classifier_bounds <- list(f1, f2, f3, f4, f5, f6, f7, f8, f9)
binary_classifier_table <- data.frame("Description" = character(), "Dataset Size" = integer(), "Degree" = numeric(), "Cost" = numeric(),
                                      "Average CV Accuracy" = numeric(), "Best Accuracy" = numeric(), stringsAsFactors = FALSE)
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    negative_class <- bound[[1]]
    positive_class <- bound[[2]]
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- abalone_df
    # CREATE SUBSET BASED ON BOUNDS
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    # CHANGE PROBLEM TO A BINARY CLASSIFIER BASED ON BOUNDS
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            # BUILD MODEL FOR GIVEN COMBINATION OF D AND C
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            # FIND BEST ACCURACY
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    # APPEND BINARY CLASSIFIER TABLE: DESCRIPTION, TRAINING SET SIZE, BEST D, BEST C, AVERAGE CV ACC, BEST ACC
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy)
    # APPEND BINARY CLASSIFIER MODEL LIST: THESE ARE THE QUERY NODES
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- best_model
}
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_cv_accuracy <- 0
best_predictions <- data.frame()
binary_classifier_models <- list()
for (bound in classifier_bounds) {
    # CALCULATE BEST PARAMATERS GIVEN THE BINARY PARTITION BOUNDS AND APPEND TO CLASSIFIER PARAMS DATAFRAME
    negative_class <- bound[[1]]
    positive_class <- bound[[2]]
    description <- ""
    if (length(negative_class) > 2) {
        description <- paste(description, "<= ", negative_class[length(negative_class)])
    } else if (length(negative_class) == 2) {
        description <- paste(description, negative_class[1], "-", negative_class[2])
    } else {
        description <- paste(description, negative_class[1])
    }
    description <- paste(description, " vs ")
    if (length(positive_class) > 2) {
        description <- paste(description, ">= ", positive_class[length(positive_class)])
    } else if (length(positive_class) == 2) {
        description <- paste(description, positive_class[1], "-", positive_class[2])
    } else {
        description <- paste(description, positive_class[1])
    }
    df <- abalone_df
    # CREATE SUBSET BASED ON BOUNDS
    df <- df[df$Rings %in% negative_class | df$Rings %in% positive_class,]
    # CHANGE PROBLEM TO A BINARY CLASSIFIER BASED ON BOUNDS
    df$Rings[df$Rings %in% negative_class] <- -1
    df$Rings[df$Rings %in% positive_class] <- 1
    average_accuracy <- 0
    best_accuracy <- 0
    best_d <- 0
    best_c <- 0
    cross_fold <- 5
    num_of_combos <- length(costs) * length(degrees)
    best_model <- 0
    for (d in degrees) {
        for (c in costs) {
            # BUILD MODEL FOR GIVEN COMBINATION OF D AND C
            current_model <- svm(Rings ~ ., data = df, kernel = "polynomial", degree = d, type = "C-classification", cost = c, cross = cross_fold)
            average_accuracy = average_accuracy + current_model$tot.accuracy
            # FIND BEST ACCURACY
            if (current_model$tot.accuracy > best_accuracy) {
                best_accuracy <- current_model$tot.accuracy
                best_d <- d
                best_c <- c
                best_model <- current_model
            }
        }
    }
    # APPEND BINARY CLASSIFIER TABLE: DESCRIPTION, TRAINING SET SIZE, BEST D, BEST C, AVERAGE CV ACC, BEST ACC
    binary_classifier_table[nrow(binary_classifier_table) + 1,] <- c(description, nrow(df), best_d, best_c, average_accuracy / num_of_combos, best_accuracy)
    # APPEND BINARY CLASSIFIER MODEL LIST: THESE ARE THE QUERY NODES
    binary_classifier_models[[length(binary_classifier_models) + 1]] <- best_model
}
print(binary_classifier_table)
sum(abalone_df[abalone_df$Rings == 8 | abalone_df$Rings == 9])
sum(abalone_df[abalone_df$Rings == 8 | abalone_df$Rings == 9, ])
sum(abalone_df[abalone_df$Rings == 8 | abalone_df$Rings == 9])
abalone_df[abalone_df$Rings==8]
abalone_df[abalone_df$Rings==8,]
length(abalone_df[abalone_df$Rings==8,])
length(abalone_df[abalone_df$Rings==9,])
nrow(abalone_df[abalone_df$Rings==8,]) + nrow(abalone_df[abalone_df$Rings==9,])
binary
binary_classifier_table
final_predictions <- c()
for (i in 1:nrow(abalone_df)) {
    # <= 9 or >= 10
    model <- binary_classifier_models[[1]]
    prediction <- predict(model, abalone_df[i, - length(abalone_df)])
    if (prediction == 1) {
        # prediction >= 10
        # 10-11 or >= 12
        model <- binary_classifier_models[[6]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction >= 12
            # 12-13 or >= 14
            model <- binary_classifier_models[[7]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 14
                final_predictions <- c(final_predictions, 14)
            } else {
                # 12 or 13
                model <- binary_classifier_models[[9]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 13
                    final_predictions <- c(final_predictions, 13)
                } else {
                    # final prediction is 12
                    final_predictions <- c(final_predictions, 12)
                }
            }
        } else {
            # prediction 10-11
            model <- binary_classifier_models[[8]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 11
                final_predictions <- c(final_predictions, 11)
            } else {
                # final prediction is 10
                final_predictions <- c(final_predictions, 10)
            }
        }
    } else if (prediction == -1){
        # prediction <= 9
        # <= 7 or 8-9
        model <- binary_classifier_models[[2]]
        prediction <- predict(model, abalone_df[i, - length(abalone_df)])
        if (prediction == 1) {
            # prediction 8-9
            model <- binary_classifier_models[[4]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # final prediction is 9
                final_predictions <- c(final_predictions, 9)
            } else {
                # final prediction is 8
                final_predictions <- c(final_predictions, 8)
            }
        } else {
            # prediction <= 7
            # <= 5 or 6-7
            model <- binary_classifier_models[[3]]
            prediction <- predict(model, abalone_df[i, - length(abalone_df)])
            if (prediction == 1) {
                # prediction 6-7
                model <- binary_classifier_models[[5]]
                prediction <- predict(model, abalone_df[i, - length(abalone_df)])
                if (prediction == 1) {
                    # final prediction is 7
                    final_predictions <- c(final_predictions, 7)
                } else {
                    # final prediction is 6
                    final_predictions <- c(final_predictions, 6)
                }
            } else {
                # final prediction is 5
                final_predictions <- c(final_predictions, 5)
            }
        }
    }
}
binary_class_accuracy <- mean(final_predictions == abalone_df$Rings) * 100
binary_class_distances <- abs(final_predictions - abalone_df$Rings)
binary_average_distance <- mean(binary_class_distances)
binary
binary
binary_class_accuracy
hist(binary_class_distances, main = "Histogram of Binary Class Distances", xlab = "Distance", ylab = "Frequency", xlim = c(0, 8))
axis(side = 1, at = seq(0, 10, 1), labels = seq(0, 10, 1))
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entire <- sqrt(sum(predictions - reg_df$Y)^2 / nrow(reg_df))
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, reg_model_entire$tot.MSE)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, reg_model_entire$tot.MSE)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}

# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entre <- mean((predictions - reg_df$Y) ^ 2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entre <- mean((predictions - reg_df$Y) ^ 2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
epsilons <- seq(1, 1.75, .25)
epsilons
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(1, 1.75, .05)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
epsilons <- seq(1, 1.75, .05)
epsilons
reg_costs
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(1, 1.75, .05)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entre <- mean((predictions - reg_df$Y) ^ 2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(1, 1.75, .05)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entre <- mean((predictions - reg_df$Y) ^ 2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entre <- mean((predictions - reg_df$Y) ^ 2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c)
        predictions <- predict(reg_model_entire, reg_df)
        mse_entre <- mean((predictions - reg_df$Y) ^ 2)
        print(mse_entire)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table

# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
max(reg_df$Y)
min(reg_df$Y)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(0.1, 1.8, 0.02)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
print(reg_accuracies_table)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(0.1, 1.5, 0.04)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
print(reg_accuracies_table)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(0.1, 1.8, 0.04)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
print(reg_accuracies_table)
library(e1071)
library(e1071)
#EXERCISE 1
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_cv_accuracy <- 0
best_predictions <- data.frame()
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- seq(0.1, 1.8, 0.04)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
print(reg_accuracies_table)
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10^(-1:3))
epsilons <- seq(0.1, 1.8, 0.04)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data
reg_costs
epsilons
reg_accuracies_table
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10^(-1:3))
epsilons <- seq(0.1, 1.8, 0.04)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}

# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10^(-1:3))
epsilons <- seq(0.1, 1.8, 0.04)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        mse_entire <- mean(reg_model_entire$residuals^2)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, mse_entire)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
reg_accuracies_table <- data.frame("Epsilon" = integer(), "Cost" = numeric(), "CV MSE" = numeric(), "Entire DF MSE" = numeric(), stringsAsFactors = FALSE)
# epsilon values 1.5 and 1.75
for (c in reg_costs) {
    for (e in epsilons) {
        # BUILD MODEL AND CALCULATE MSE OVER ENTIRE DATASET
        reg_model_entire <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 100)
        # BUILD MODEL USING 10-FOLD CROSSVALIDATION
        reg_model <- svm(Y ~ X, data = reg_df, kernel = "polynomial", degree = 2, type = "eps-regression", epsilon = e, cost = c, cross = 10)
        reg_accuracies_table[nrow(reg_accuracies_table) + 1,] <- c(e, c, reg_model$tot.MSE, reg_model_entire$tot.MSE)
        if (reg_model$tot.MSE < lowest_mse) {
            lowest_mse = reg_model$tot.MSE
            best_reg_c <- c
            best_reg_e <- e
            best_reg_model <- reg_model
        }
    }
}
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Epsilon),]
reg_accuracies_table <- reg_accuracies_table[order(reg_accuracies_table$Cost),]
reg_accuracies_table
reg_max_combination <- reg_accuracies_table[which.min(reg_accuracies_table$CV.MSE),]
reg_max_combination
reg_min_combination <- reg_accuracies_table[which.min(reg_accuracies_table$CV.MSE),]
reg_min_combination
# combination with the CV highest accuracy
reg_min_combination <- reg_accuracies_table[which.min(reg_accuracies_table$CV.MSE),]
plot(reg_df, pch = 16)
test_data <- data.frame(seq(0, 10, length.out = 1000))
colnames(test_data) <- c("X")
predicted <- predict(best_reg_model, test_data)
points(test_data$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
plot(reg_df, pch = 16)
test_data <- data.frame(seq(0, 10, length.out = 1000))
colnames(test_data) <- c("X")
predicted <- predict(best_reg_model, test_data)
points(test_data$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")
legend("Original Data", "Predicted Line with 1000 points")
plot(reg_df, pch = 16)
legend("Original Data", "Predicted Line with 1000 points")
test_data <- data.frame(seq(0, 10, length.out = 1000))
colnames(test_data) <- c("X")
predicted <- predict(best_reg_model, test_data)
points(test_data$X, predicted, col = "red", pch = 4)
title("Data Points with Fitted Line")

#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilons = e, costs = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances")
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances")
#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
degrees <- c(1:3)
# IMPORTLIBRARY
#install.packages("e1071")
library(e1071)
#EXERCISE 1
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_cv_accuracy <- 0
best_predictions <- data.frame()
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
# IMPORTLIBRARY
#install.packages("e1071")
library(e1071)
#EXERCISE 1
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", "Shucked", "Viscera", "Shell", "Rings")
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
best_cv_accuracy <- 0
best_predictions <- data.frame()
# EXERCISE 4
reg_df <- read.csv("Exercise-4.csv")
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75)
lowest_mse <- 1000
best_reg_c <- 0
best_reg_e <- 0
best_reg_model <- 0
#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
epsilons <- c(0.25, 0.5, 0.75, 1)
degrees <- c(1:3)
reg_costs <- c(10 ^ (-1:3))
length(d#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75, 1)
degrees <- c(1:3))
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
epsilons <- c(0.25, 0.5, 0.75, 1)
degrees <- c(1:3)
reg_costs <- c(10 ^ (-1:3))
reg_cross_fold <- 10
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
reg_cross_fold <- 10
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75, 1)
degrees <- c(1:3)
length(degrees) * length(epsilons) * length(reg_costs)
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances")
#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75)
degrees <- c(1:3)
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
library(e1071)
# EXERCISE 1
# READ IN ABALONE DATA SET AND SET THE COLUMN NAMES BASED ON DATA DESCRIPTION
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", 
    "Shucked", "Viscera", "Shell", "Rings")
# INITIALIZE LEARNING PARAMETERS
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
# KEEP TRACK OF BEST CV ACCURACY AND THE BEST RESPECTIVE PREDICTIONS
best_cv_accuracy <- 0
best_predictions <- data.frame()
# INITIALIZE TABLE (DATA FRAME TO BE APPENDED)
accuracies_table <- data.frame("Degree" = integer(), "Cost" = numeric(),
     "CV Accuracy" = numeric(), "Entire DF Accuracy" = numeric(), 
     stringsAsFactors = FALSE)
#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75)
degrees <- c(1:3)
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
library(e1071)
# EXERCISE 1
# READ IN ABALONE DATA SET AND SET THE COLUMN NAMES BASED ON DATA DESCRIPTION
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", 
    "Shucked", "Viscera", "Shell", "Rings")
# INITIALIZE LEARNING PARAMETERS
degrees <- c(1:3)
costs <- c(10 ^ (-1:2))
cross_fold <- 5
# KEEP TRACK OF BEST CV ACCURACY AND THE BEST RESPECTIVE PREDICTIONS
best_cv_accuracy <- 0
best_predictions <- data.frame()
# INITIALIZE TABLE (DATA FRAME TO BE APPENDED)
accuracies_table <- data.frame("Degree" = integer(), "Cost" = numeric(),
     "CV Accuracy" = numeric(), "Entire DF Accuracy" = numeric(), 
     stringsAsFactors = FALSE)
#EXERCISE 6
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75)
degrees <- c(1:3)
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            print(reg_model$tot.MSE)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
# AVERAGE DISTANCE OF THE PREDICTED CLASS FROM THE TRUE CLASS
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
library(e1071)
# EXERCISE 1
# READ IN ABALONE DATA SET AND SET THE COLUMN NAMES BASED ON DATA DESCRIPTION
abalone_df <- read.table("abalone.data", sep = ",", header = FALSE)
colnames(abalone_df) <- c("Sex", "Length", "Diam", "Height", "Whole", 
    "Shucked", "Viscera", "Shell", "Rings")
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
# EXERCISE 6
# INITIALIZE LEARNING PARAMETERS
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:3))
epsilons <- c(0.25, 0.5, 0.75)
degrees <- c(1:3)
# KEEP TRACK OF PARAMS THAT PRODUCE LOWEST MSE
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(df)])
library(e1071)
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(abalone_df)])
best_reg_abalone
best_reg_model_abalone
# INITIALIZE LEARNING PARAMETERS
reg_cross_fold <- 5
reg_costs <- c(10 ^ (-1:2))
epsilons <- c(0.25, 0.5, 0.75)
degrees <- c(1:3)
# KEEP TRACK OF PARAMS THAT PRODUCE LOWEST MSE
best_reg_c_abalone <- 0
best_reg_e_abalone <- 0
best_reg_d_abalone <- 0
best_reg_model_abalone <- 0
lowest_mse_abalone <- 1000
best_reg_model_abalone <- 0
for (c in reg_costs) {
    for (e in epsilons) {
        for (d in degrees) {
            reg_model <- svm(Rings ~ ., abalone_df, kernel = "polynomial", degree = d, type = "eps-regression", epsilon = e, cost = c, cross = reg_cross_fold)
            print(reg_model$tot.MSE)
            if (reg_model$tot.MSE < lowest_mse_abalone) {
                lowest_mse_abalone = reg_model$tot.MSE
                best_reg_c_abalone <- c
                best_reg_e_abalone <- e
                best_reg_d_abalone <- d
                best_reg_model_abalone <- reg_model
            }
        }
    }
}
best_reg_model_abalone
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(abalone_df)])
predicted_reg_abalonew
predicted_reg_abalone
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(abalone_df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
average_distance_reg_abalone <- mean(reg_abalone_distances)
predicted_reg_abalone <- as.numeric(predicted_reg_abalone)
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
predicted_reg_abalone <- predict(best_reg_model_abalone, abalone_df[, - length(abalone_df)])
predicted_reg_abalone <- as.numeric(predicted_reg_abalone)
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df[, length(df)])
reg_abalone_distances <- abs(predicted_reg_abalone - abalone_df$Rings)
average_distance_reg_abalone <- mean(reg_abalone_distances)
average_distance_reg_abalone
# HISTOGRAM OF FREQUENCY OF DISTANCES FROM THE TRUE CLASS
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances")
# HISTOGRAM OF FREQUENCY OF DISTANCES FROM THE TRUE CLASS
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances",
    xlab = "Distance", ylab = "Frequency", xlim = c(0, 8))
axis(side = 1, at = seq(0, 10, 1), labels = seq(0, 10, 1))
# HISTOGRAM OF FREQUENCY OF DISTANCES FROM THE TRUE CLASS
hist(reg_abalone_distances, main = "Histogram of Abalone Regression Distances",
    xlab = "Distance", ylab = "Frequency", xlim = c(0, 10))
axis(side = 1, at = seq(0, 10, 1), labels = seq(0, 10, 1))
